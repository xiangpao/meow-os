import streamlit as st
import google.generativeai as genai
import os
import time
import tempfile
import base64
from PIL import Image
from utils import analyze_audio_advanced, extract_audio_from_video

# --- 0. ç³»ç»Ÿé…ç½® ---
st.set_page_config(
    page_title="ğŸ± å–µæ˜Ÿç”µæ³¢å°", 
    page_icon="ğŸ“¡", 
    layout="centered", 
    initial_sidebar_state="collapsed"
)

if "HTTP_PROXY" in os.environ: del os.environ["HTTP_PROXY"]
if "HTTPS_PROXY" in os.environ: del os.environ["HTTPS_PROXY"]

# --- 1. è®°å¿†åˆå§‹åŒ– ---
if 'baseline_pitch' not in st.session_state:
    st.session_state['baseline_pitch'] = None

if 'latest_analysis' not in st.session_state:
    st.session_state['latest_analysis'] = None

# --- 2. CSS æ‹¿é“é£æ·±åº¦å®šåˆ¶ (è§†è§‰å›å½’) ---
st.markdown("""
<style>
    /* å…¨å±€èƒŒæ™¯ï¼šçƒ­ç‰›å¥¶ç™½ -> æµ…æ‹¿é“æ¸å˜ */
    .stApp {
        background: linear-gradient(180deg, #FFFDF7 0%, #F5E6D3 100%);
        color: #4E342E;
    }
    
    /* æ ‡é¢˜æ ·å¼ï¼šåœ†æ¶¦ã€æ·±å’–å•¡è‰² */
    h1 { 
        color: #5D4037 !important; 
        font-family: 'Comic Sans MS', 'ZKKuaiLe', 'å¹¼åœ†', sans-serif !important;
        font-weight: 800;
        text-shadow: 2px 2px 0px #FFF;
    }
    
    /* å›¾ç‰‡å®¹å™¨å±…ä¸­ */
    .header-img {
        display: flex;
        justify_content: center;
        align-items: center;
        margin-bottom: 10px;
    }
    
    /* å¡ç‰‡/æŠ˜å é¢æ¿/ä¸Šä¼ æ¡†ï¼šåƒä¸€å—ç™½è‰²çš„æ–¹ç³– */
    .stExpander, .css-1r6slb0, [data-testid="stFileUploadDropzone"], .stSelectbox > div > div {
        background-color: #FFFFFF !important;
        border-radius: 20px !important;
        border: 2px solid #EFEBE9 !important;
        box-shadow: 0 4px 12px rgba(93, 64, 55, 0.1) !important;
    }
    
    /* æŒ‰é’®ï¼šç„¦ç³–è‰²æœå†»è´¨æ„Ÿ */
    .stButton>button {
        width: 100%;
        background: linear-gradient(45deg, #D2691E, #8B4513);
        color: white;
        border-radius: 25px;
        height: 55px;
        font-size: 18px;
        font-weight: bold;
        border: none;
        box-shadow: 0 4px 10px rgba(139, 69, 19, 0.3);
        transition: all 0.3s;
    }
    .stButton>button:hover {
        transform: scale(1.02);
        box-shadow: 0 6px 15px rgba(139, 69, 19, 0.5);
        background: linear-gradient(45deg, #E67E22, #A0522D);
    }
    
    /* Tab æ ‡ç­¾é¡µï¼šæœªé€‰ä¸­æ˜¯æµ…å’–ï¼Œé€‰ä¸­æ˜¯æ·±å’– */
    .stTabs [data-baseweb="tab"] {
        background-color: #F5E6D3;
        border-radius: 15px 15px 0 0;
        color: #5D4037;
        font-weight: bold;
    }
    .stTabs [aria-selected="true"] {
        background-color: #FFFFFF;
        border-top: 3px solid #D2691E;
        color: #D2691E;
    }
    
    /* å­—ä½“é¢œè‰²ä¼˜åŒ– */
    p, label, .stMarkdown, li, .stCaption {
        color: #4E342E !important;
        font-family: 'PingFang SC', 'Microsoft YaHei', sans-serif;
    }
    
    /* éšè—ä¸Šä¼ ç»„ä»¶è‡ªå¸¦çš„ä¸‘è¾¹æ¡† */
    [data-testid="stFileUploadDropzone"] {
        border: 2px dashed #D7CCC8 !important;
    }
</style>
""", unsafe_allow_html=True)

# --- 3. é¡¶éƒ¨çœ‹æ¿ (ä¿®å¤ï¼šä½¿ç”¨æœ¬åœ° logo.gif) ---
def render_local_gif(filename, width=180):
    """è¯»å–æœ¬åœ° GIF å¹¶ä»¥ Base64 æ˜¾ç¤ºï¼Œç¡®ä¿åŠ¨å›¾ä¸é»‘å±"""
    try:
        if os.path.exists(filename):
            with open(filename, "rb") as f:
                data = f.read()
            b64 = base64.b64encode(data).decode()
            return f'<div class="header-img"><img src="data:image/gif;base64,{b64}" width="{width}" style="border-radius:15px"></div>'
        else:
            # å¤‡ç”¨ï¼šå¦‚æœæœ¬åœ°æ²¡æ–‡ä»¶ï¼Œæ˜¾ç¤ºä¸€ä¸ªç½‘ç»œå…œåº•å›¾
            return f'<div class="header-img"><img src="https://media.giphy.com/media/GeimqsH0TLDt4tScGw/giphy.gif" width="{width}"></div>'
    except:
        return ""

# æ˜¾ç¤ºé¡¶éƒ¨ Logo
st.markdown(render_local_gif("logo.gif", width=200), unsafe_allow_html=True)

st.title("ğŸ± å–µæ˜Ÿç”µæ³¢å°")
st.markdown("<p style='text-align: center; margin-top: -15px; color: #8D6E63;'><i>â€”â€” æ¥æ”¶æ¥è‡ª 50Hz é¢‘æ®µçš„åŠ å¯†å¿ƒå£° â€”â€”</i></p>", unsafe_allow_html=True)

# --- 4. ç§‘å­¦åŸç† (æ‰¾å›åŠŸèƒ½) ---
with st.expander("ğŸ”¬ å–µæ˜Ÿå‘å£°å­¦åŸç† (Science)", expanded=False):
    st.markdown("""
    **æœ¬å°è§£ç ç®—æ³•åŸºäºç‘å…¸éš†å¾·å¤§å­¦ Susanne SchÃ¶tz æ•™æˆçš„çŒ«è¯­æ—‹å¾‹å­¦ç ”ç©¶ï¼š**
    * **ğŸµ å‡è°ƒ (Rising Pitch â†—)**: ç±»ä¼¼äººç±»çš„ç–‘é—®å¥ï¼Œé€šå¸¸ä»£è¡¨**è¯·æ±‚ (Soliciting)** æˆ– **å‹å¥½çš„ç¡®è®¤**ã€‚
    * **ğŸµ é™è°ƒ (Falling Pitch â†˜)**: ç±»ä¼¼äººç±»çš„é™ˆè¿°å¥ï¼Œé€šå¸¸ä»£è¡¨**æ‹’ç»**ã€**å‹åŠ›**æˆ–**è‡ªä¿¡çš„é™ˆè¿°**ã€‚
    * **â³ æ—¶é•¿ (Duration)**: 
        * çŸ­ä¿ƒéŸ³ (<0.5s): ç¤¾äº¤é—®å€™ / ç¡®è®¤å­˜åœ¨ã€‚
        * é•¿éŸ³ (>1.0s): å¼ºçƒˆéœ€æ±‚ (æˆ‘è¦åƒ!) / æŠ±æ€¨ (æ”¾æˆ‘å‡ºå»!)ã€‚
    """)

# --- 5. æ ¸å¿ƒæ§åˆ¶å° (åœºæ™¯å¿…é€‰) ---
st.markdown("### ğŸ›ï¸ ä¿¡å·æ§åˆ¶å°")

# åœºæ™¯é€‰æ‹©ï¼šç§»å‡ºæŠ˜å åŒºï¼Œå¼ºåˆ¶é€‰æ‹©
scenario_options = [
    "ğŸš« è¯·é€‰æ‹©å‘å°„æº (å¿…é€‰)", 
    "ğŸ½ï¸ å¹²é¥­æ—¶åˆ» (Food)", 
    "ğŸšª é—¨çª—/å—é˜» (Barrier)", 
    "ğŸ›‹ï¸ è´´è´´/æ±‚æ‘¸ (Affection)", 
    "ğŸ¥ å®³æ€•/åº”æ¿€ (Stress)", 
    "ğŸ¦‹ çŒæ€æ—¶åˆ» (Hunting)", 
    "ğŸ˜¡ åˆ«æŒ¨è€å­ (Warning)", 
    "ğŸŒ™ æ·±å¤œè·‘é…· (Night)"
]
context = st.selectbox("ğŸ“ 1. é”å®šä¿¡å·å‘å°„æº (å¿…é€‰)", scenario_options, label_visibility="collapsed")

# æ ¡å‡†åŠŸèƒ½ (ä¾ç„¶æŠ˜å ï¼Œä¿æŒæ•´æ´)
with st.expander("âš™ï¸ é«˜çº§è®¾ç½®ï¼šå£°çº¹æ ¡å‡†", expanded=False):
    st.caption("ä¸Šä¼ ä¸€æ®µâ€œå¹³æ—¶æœ€æ”¾æ¾çš„å–µå«â€ä½œä¸ºåŸºå‡†ï¼Œæé«˜è¯†åˆ«ç‡ã€‚")
    calib_file = st.file_uploader("ä¸Šä¼ æ ¡å‡†å½•éŸ³", type=["wav", "mp3", "m4a", "aac"], key="cal_up", label_visibility="collapsed")
    
    if calib_file:
        if st.button("âš¡ è®¾ä¸ºåŸºå‡†"):
            with st.spinner("æ ¡å‡†ä¸­..."):
                cal_data = analyze_audio_advanced(calib_file, baseline_pitch=None)
                if cal_data['status'] != 'error':
                    st.session_state['baseline_pitch'] = cal_data['mean_pitch']
                    st.success(f"âœ… å·²æ ¡å‡†: {cal_data['mean_pitch']}Hz")
                    time.sleep(1)
                    st.rerun()
                else:
                    st.error("æ ¡å‡†å¤±è´¥ï¼Œè¯·é‡è¯•")
    
    # çŠ¶æ€æ˜¾ç¤º
    col_s, col_c = st.columns([3,1])
    with col_s:
        if st.session_state['baseline_pitch']:
            st.success(f"å½“å‰åŸºå‡†: {st.session_state['baseline_pitch']}Hz")
        else:
            st.info("å°šæœªå½•å…¥åŸºå‡†")
    with col_c:
        if st.button("æ¸…é™¤"):
            st.session_state['baseline_pitch'] = None
            st.rerun()

# --- è¿æ¥äº‘ç«¯ ---
ai_ready = False
# å®šä¹‰ç­‰å¾…ç”¨çš„â€œæ‰“å­—çŒ«â€åŠ¨ç”» (ä»…ç½‘ç»œé“¾æ¥ï¼Œç”¨äº st.image)
LOADING_GIF_URL = "https://media.tenor.com/4JPf4v6sHjIAAAAj/bongo-cat-typing.gif"

try:
    if "GOOGLE_API_KEY" in st.secrets:
        api_key = st.secrets["GOOGLE_API_KEY"]
        genai.configure(api_key=api_key)
        # ä½¿ç”¨ä½ éªŒè¯è¿‡çš„ç¨³å¥æ¨¡å‹
        model = genai.GenerativeModel(
            model_name='gemini-flash-latest',
            system_instruction="ä½ æ˜¯ä¸€åªçŒ«ã€‚ç”¨ç¬¬ä¸€äººç§°ï¼ˆ'æœ¬å–µ'ã€'æˆ‘'ï¼‰ã€‚ç¦æ­¢è§£é‡Šã€‚è¯­æ°”ç”ŸåŠ¨å‚²å¨‡ã€‚æ ¹æ®åœºæ™¯å’Œå£°éŸ³ç‰¹å¾ç¿»è¯‘å¿ƒå£°ã€‚"
        )
        ai_ready = True
    else:
        st.error("âš ï¸ å¯†é’¥ç¼ºå¤±")
except Exception:
    st.error("âš ï¸ AI åˆå§‹åŒ–å¤±è´¥")

# --- 6. ä¸šåŠ¡åŠŸèƒ½åŒº ---
st.markdown("### ğŸ“¡ ä¿¡å·æ¥æ”¶åŒº")
tab1, tab2 = st.tabs(["ğŸ™ï¸ è¯­éŸ³è§£ç ", "ğŸ“¹ è§†é¢‘è§£ç "])

# === Tab 1: è¯­éŸ³ ===
with tab1:
    audio_file = st.file_uploader("ä¸Šä¼ éŸ³é¢‘", type=["wav", "mp3", "m4a", "aac"], key="audio_up", label_visibility="collapsed")
    
    with st.expander("ğŸ“· (å¯é€‰) å¢åŠ ç…§ç‰‡è¾…åŠ©", expanded=False):
        img_cam = st.camera_input("æ‹ç…§")
        img_up = st.file_uploader("æˆ–ä¸Šä¼ å›¾ç‰‡", type=["jpg", "png"], key="img_up")
    img_final = img_cam if img_cam else img_up

    if st.button("â–¶ï¸ å¼€å§‹è§£ç ", key="btn_audio"):
        # å¼ºåˆ¶æ£€æŸ¥åœºæ™¯
        if "ğŸš«" in context:
            st.error("âš ï¸ æ— æ³•è§£ç ï¼šè¯·å…ˆåœ¨ä¸Šæ–¹æ§åˆ¶å°é€‰æ‹©ã€ä¿¡å·å‘å°„æºã€‘ï¼")
        elif not audio_file:
            st.error("âš ï¸ è¯·å…ˆä¸Šä¼ å–µå«å£°ï¼")
        else:
            # === ç­‰å¾…ç‰¹æ•ˆ (åœ¨ä¸‹æ–¹æ˜¾ç¤ºï¼Œä¸æ›¿æ¢ Header) ===
            loading = st.empty()
            
            # é˜¶æ®µ 1
            with loading.container():
                st.markdown(f'<div class="header-img"><img src="{LOADING_GIF_URL}" width="150"></div>', unsafe_allow_html=True)
                st.info("ğŸ“¡ æ­£åœ¨è¿æ¥å–µæ˜ŸåŸºç«™ (50Hz)...")
                st.progress(20)
            
            data = analyze_audio_advanced(audio_file, st.session_state['baseline_pitch'])
            
            # é˜¶æ®µ 2
            with loading.container():
                st.markdown(f'<div class="header-img"><img src="{LOADING_GIF_URL}" width="150"></div>', unsafe_allow_html=True)
                st.info("ğŸˆ æ­£åœ¨ç ´è¯‘åŠ å¯†ç”µæ³¢...")
                st.progress(60)

            if data['status'] == 'error':
                loading.empty()
                st.error(f"âŒ å¤±è´¥: {data['msg']}")
            else:
                ai_result = ""
                if ai_ready:
                    try:
                        prompt = f"åœºæ™¯ï¼š{context}ã€‚å£°å­¦ç‰¹å¾ï¼š{data}ã€‚ç¿»è¯‘æˆ‘çš„å¿ƒå£°ã€‚"
                        inputs = [prompt]
                        if img_final: inputs.append(Image.open(img_final))
                        ai_result = model.generate_content(inputs).text
                    except: 
                        st.warning("äº‘ç«¯è¿æ¥ä¸ç¨³å®šï¼Œè½¬ä¸ºç¦»çº¿æ¨¡å¼ã€‚")

                loading.empty() # æ¸…é™¤ç­‰å¾…åŠ¨ç”»

                # ç»“æœå±•ç¤º
                st.success("âœ… è§£ç æˆåŠŸ")
                c1, c2, c3 = st.columns(3)
                c1.metric("æƒ…ç»ª", data['pitch_trend'].split()[0])
                c2.metric("æ—¶é•¿", f"{data['duration']}s")
                c3.metric("éŸ³é«˜", f"{data['mean_pitch']}Hz")

                st.markdown("### ğŸ± ä¸»å­è¯´ï¼š")
                if ai_result:
                    st.info(f"â€œ {ai_result} â€")
                else:
                    st.info(f"ğŸ¤– æœ¬åœ°æ¨æ–­ï¼šè¿™ä¼¼ä¹æ˜¯ã€{data['pitch_trend']}ã€‘çš„æ„æ€ã€‚")

# === Tab 2: è§†é¢‘ ===
with tab2:
    video_file = st.file_uploader("ä¸Šä¼ è§†é¢‘", type=["mp4", "mov", "avi", "m4v"], key="video_up", label_visibility="collapsed")

    if st.button("â–¶ï¸ åˆ†æè§†é¢‘", key="btn_video"):
        if "ğŸš«" in context:
            st.error("âš ï¸ æ— æ³•è§£ç ï¼šè¯·å…ˆåœ¨ä¸Šæ–¹æ§åˆ¶å°é€‰æ‹©ã€ä¿¡å·å‘å°„æºã€‘ï¼")
        elif not video_file:
            st.error("âš ï¸ è¯·å…ˆä¸Šä¼ è§†é¢‘ï¼")
        else:
            loading = st.empty()
            with loading.container():
                st.markdown(f'<div class="header-img"><img src="{LOADING_GIF_URL}" width="150"></div>', unsafe_allow_html=True)
                st.info("ğŸï¸ æ­£åœ¨åˆ†ç¦»éŸ³è½¨ & é€å¸§è§£æ...")
                st.progress(30)

            tfile = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
            tfile.write(video_file.read())
            video_path = tfile.name
            audio_path = video_path.replace(".mp4", ".wav")
            
            has_audio = extract_audio_from_video(video_path, audio_path)
            
            if not has_audio:
                loading.empty()
                st.error("âŒ è§†é¢‘æ— å£°éŸ³")
            else:
                data = analyze_audio_advanced(audio_path, st.session_state['baseline_pitch'])
                ai_msg = ""
                if ai_ready:
                    with loading.container():
                        st.markdown(f'<div class="header-img"><img src="{LOADING_GIF_URL}" width="150"></div>', unsafe_allow_html=True)
                        st.info("ğŸ§  AI å¤§è„‘ç–¯ç‹‚è¿è½¬ä¸­...")
                        st.progress(80)
                    try:
                        video_blob = genai.upload_file(video_path)
                        while video_blob.state.name == "PROCESSING":
                            time.sleep(1)
                            video_blob = genai.get_file(video_blob.name)
                        
                        prompt = f"åœºæ™¯ï¼š{context}ã€‚å£°éŸ³ï¼š{data}ã€‚ç¿»è¯‘å¿ƒå£°ã€‚"
                        response = model.generate_content([prompt, video_blob])
                        ai_msg = response.text
                    except: pass
                
                loading.empty()
                st.success("âœ… å®Œæˆ")
                st.video(video_file)
                st.markdown("### ğŸ± ä¸»å­è¯´ï¼š")
                if ai_msg:
                    st.info(f"â€œ {ai_msg} â€")
                else:
                    st.info("AI æš‚æ—¶ç¦»çº¿ã€‚")
            
            try:
                os.remove(video_path)
                os.remove(audio_path)
            except: pass
