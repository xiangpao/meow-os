import streamlit as st
import google.generativeai as genai
import os
import time
import tempfile
import base64
from PIL import Image
from utils import analyze_audio_advanced, extract_audio_from_video

# --- 0. ç³»ç»Ÿé…ç½® ---
st.set_page_config(
    page_title="ğŸ± å–µæ˜Ÿç”µæ³¢å°", 
    page_icon="ğŸ“¡", 
    layout="centered", 
    initial_sidebar_state="collapsed"
)

if "HTTP_PROXY" in os.environ: del os.environ["HTTP_PROXY"]
if "HTTPS_PROXY" in os.environ: del os.environ["HTTPS_PROXY"]

# --- 1. è®°å¿†åˆå§‹åŒ– ---
if 'baseline_pitch' not in st.session_state:
    st.session_state['baseline_pitch'] = None

if 'latest_analysis' not in st.session_state:
    st.session_state['latest_analysis'] = None

# --- 2. CSS æ‹¿é“é£æ·±åº¦å®šåˆ¶ ---
st.markdown("""
<style>
    /* å…¨å±€èƒŒæ™¯ */
    .stApp {
        background: linear-gradient(180deg, #FFFDF7 0%, #F5E6D3 100%);
        color: #4E342E;
    }
    h1 { 
        color: #5D4037 !important; 
        font-family: 'Comic Sans MS', 'ZKKuaiLe', 'å¹¼åœ†', sans-serif !important;
        font-weight: 800;
        text-shadow: 2px 2px 0px #FFF;
    }
    /* å›¾ç‰‡å®¹å™¨ */
    .header-img {
        display: flex;
        justify_content: center;
        align-items: center;
        margin-bottom: 10px;
    }
    /* å¡ç‰‡æ ·å¼ */
    .stExpander, .css-1r6slb0, [data-testid="stFileUploadDropzone"], .stSelectbox > div > div {
        background-color: #FFFFFF !important;
        border-radius: 20px !important;
        border: 2px solid #EFEBE9 !important;
        box-shadow: 0 4px 12px rgba(93, 64, 55, 0.1) !important;
    }
    /* æŒ‰é’®æ ·å¼ */
    .stButton>button {
        width: 100%;
        background: linear-gradient(45deg, #D2691E, #8B4513);
        color: white;
        border-radius: 25px;
        height: 55px;
        font-size: 18px;
        font-weight: bold;
        border: none;
        box-shadow: 0 4px 10px rgba(139, 69, 19, 0.3);
        transition: all 0.3s;
    }
    .stButton>button:hover {
        transform: scale(1.02);
        box-shadow: 0 6px 15px rgba(139, 69, 19, 0.5);
        background: linear-gradient(45deg, #E67E22, #A0522D);
    }
    /* Tab æ ·å¼ */
    .stTabs [data-baseweb="tab"] {
        background-color: #F5E6D3;
        border-radius: 15px 15px 0 0;
        color: #5D4037;
        font-weight: bold;
    }
    .stTabs [aria-selected="true"] {
        background-color: #FFFFFF;
        border-top: 3px solid #D2691E;
        color: #D2691E;
    }
    p, label, .stMarkdown, li, .stCaption {
        color: #4E342E !important;
        font-family: 'PingFang SC', 'Microsoft YaHei', sans-serif;
    }
    [data-testid="stFileUploadDropzone"] {
        border: 2px dashed #D7CCC8 !important;
    }
</style>
""", unsafe_allow_html=True)

# --- 3. èµ„æºå®šä¹‰ ---
# (1) é¡¶éƒ¨ Logoï¼šè¯»å–æœ¬åœ° logo.gif
def render_local_logo(width=200):
    if os.path.exists("logo.gif"):
        with open("logo.gif", "rb") as f:
            b64 = base64.b64encode(f.read()).decode()
        return f'<div class="header-img"><img src="data:image/gif;base64,{b64}" width="{width}" style="border-radius:15px"></div>'
    else:
        # å…œåº•ç½‘ç»œå›¾
        return f'<div class="header-img"><img src="https://media.giphy.com/media/GeimqsH0TLDt4tScGw/giphy.gif" width="{width}"></div>'

# (2) ç­‰å¾…åŠ¨ç”»ï¼šæ‰“å­—çŒ«é“¾æ¥
LOADING_GIF = "https://media.giphy.com/media/JIX9t2j0ZTN9S/giphy.gif"

def render_loading_gif(width=150):
    return f'<div class="header-img"><img src="{LOADING_GIF}" width="{width}" style="border-radius:15px"></div>'

# --- 4. ç•Œé¢æ¸²æŸ“ ---
# é¡¶éƒ¨çœ‹æ¿ (å¸¸é©»)
st.markdown(render_local_logo(), unsafe_allow_html=True)
st.title("ğŸ± å–µæ˜Ÿç”µæ³¢å°")
st.markdown("<p style='text-align: center; margin-top: -15px; color: #8D6E63;'><i>â€”â€” æ¥æ”¶æ¥è‡ª 50Hz é¢‘æ®µçš„åŠ å¯†å–µå£° â€”â€”</i></p>", unsafe_allow_html=True)

# ç§‘å­¦åŸç†
with st.expander("ğŸ”¬ å–µæ˜Ÿå‘å£°å­¦åŸç† (Science)", expanded=False):
    st.markdown("""
    **æœ¬å°è§£ç ç®—æ³•åŸºäºç‘å…¸éš†å¾·å¤§å­¦ Susanne SchÃ¶tz æ•™æˆçš„çŒ«è¯­æ—‹å¾‹å­¦ç ”ç©¶ï¼š**
    * **ğŸµ å‡è°ƒ (Rising Pitch â†—)**: ç±»ä¼¼äººç±»çš„ç–‘é—®å¥ï¼Œé€šå¸¸ä»£è¡¨**è¯·æ±‚ (Soliciting)** æˆ– **å‹å¥½çš„ç¡®è®¤**ã€‚
    * **ğŸµ é™è°ƒ (Falling Pitch â†˜)**: ç±»ä¼¼äººç±»çš„é™ˆè¿°å¥ï¼Œé€šå¸¸ä»£è¡¨**æ‹’ç»**ã€**å‹åŠ›**æˆ–**è‡ªä¿¡çš„é™ˆè¿°**ã€‚
    * **â³ æ—¶é•¿ (Duration)**: 
        * çŸ­ä¿ƒéŸ³ (<0.5s): ç¤¾äº¤é—®å€™ / ç¡®è®¤å­˜åœ¨ã€‚
        * é•¿éŸ³ (>1.0s): å¼ºçƒˆéœ€æ±‚ (æˆ‘è¦åƒ!) / æŠ±æ€¨ (æ”¾æˆ‘å‡ºå»!)ã€‚
    * **ğŸŒŠ ç²—ç³™åº¦ (Roughness)**: å£°éŸ³å˜¶å“‘æˆ–å¸¦æ‚éŸ³ï¼Œé€šå¸¸å¯¹åº”**é˜²å¾¡**ã€**ç—›è‹¦**æˆ–**æåº¦äº¢å¥‹**ã€‚
    """)

# ä¿¡å·æ§åˆ¶å°
st.markdown("### ğŸ›ï¸ ä¿¡å·æ§åˆ¶å°")
scenario_options = [
    "ğŸš« è¯·é€‰æ‹©å‘å°„æº (å¿…é€‰)", "ğŸ½ï¸ å¹²é¥­æ—¶åˆ» (Food)", "ğŸšª é—¨çª—/å—é˜» (Barrier)", 
    "ğŸ›‹ï¸ è´´è´´/æ±‚æ‘¸ (Affection)", "ğŸ¥ å®³æ€•/åº”æ¿€ (Stress)", 
    "ğŸ¦‹ çŒæ€æ—¶åˆ» (Hunting)", "ğŸ˜¡ åˆ«æŒ¨è€å­ (Warning)", "ğŸŒ™ æ·±å¤œè·‘é…· (Night)"
]
context = st.selectbox("ğŸ“ 1. é”å®šä¿¡å·å‘å°„æº (å¿…é€‰)", scenario_options, label_visibility="collapsed")

# æ ¡å‡†è®¾ç½®
with st.expander("âš™ï¸ é«˜çº§è®¾ç½®ï¼šå£°çº¹æ ¡å‡†", expanded=False):
    calib_file = st.file_uploader("ä¸Šä¼ æ ¡å‡†å½•éŸ³", type=["wav", "mp3", "m4a", "aac"], key="cal_up", label_visibility="collapsed")
    if calib_file:
        if st.button("âš¡ è®¾ä¸ºåŸºå‡†"):
            with st.spinner("æ ¡å‡†ä¸­..."):
                cal_data = analyze_audio_advanced(calib_file, baseline_pitch=None)
                if cal_data['status'] != 'error':
                    st.session_state['baseline_pitch'] = cal_data['mean_pitch']
                    st.success(f"âœ… å·²æ ¡å‡†: {cal_data['mean_pitch']}Hz")
                    time.sleep(1)
                    st.rerun()
                else:
                    st.error("æ ¡å‡†å¤±è´¥")
    col_s, col_c = st.columns([3,1])
    with col_s:
        if st.session_state['baseline_pitch']: st.success(f"å½“å‰åŸºå‡†: {st.session_state['baseline_pitch']}Hz")
        else: st.info("å°šæœªå½•å…¥åŸºå‡†")
    with col_c:
        if st.button("æ¸…é™¤"):
            st.session_state['baseline_pitch'] = None
            st.rerun()

# --- è¿æ¥äº‘ç«¯ ---
ai_ready = False
try:
    if "GOOGLE_API_KEY" in st.secrets:
        api_key = st.secrets["GOOGLE_API_KEY"]
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel(
            model_name='gemini-flash-latest',
            system_instruction="ä½ æ˜¯ä¸€åªçŒ«ã€‚ç”¨ç¬¬ä¸€äººç§°ï¼ˆ'æœ¬å–µ'ã€'æˆ‘'ï¼‰ã€‚ç¦æ­¢è§£é‡Šã€‚è¯­æ°”ç”ŸåŠ¨å‚²å¨‡ã€‚æ ¹æ®åœºæ™¯å’Œå£°éŸ³ç‰¹å¾ç¿»è¯‘å¿ƒå£°ã€‚"
        )
        ai_ready = True
    else:
        st.error("âš ï¸ å¯†é’¥ç¼ºå¤±")
except Exception:
    st.error("âš ï¸ AI åˆå§‹åŒ–å¤±è´¥")

# --- 5. ä¸šåŠ¡åŠŸèƒ½åŒº ---
st.markdown("### ğŸ“¡ ä¿¡å·æ¥æ”¶åŒº")
tab1, tab2 = st.tabs(["ğŸ™ï¸ è¯­éŸ³è§£ç ", "ğŸ“¹ è§†é¢‘è§£ç "])

# === Tab 1: è¯­éŸ³ ===
with tab1:
    audio_file = st.file_uploader("ä¸Šä¼ éŸ³é¢‘", type=["wav", "mp3", "m4a", "aac"], key="audio_up", label_visibility="collapsed")
    
    with st.expander("ğŸ“· (å¯é€‰) å¢åŠ ç…§ç‰‡è¾…åŠ©", expanded=False):
        img_cam = st.camera_input("æ‹ç…§")
        img_up = st.file_uploader("æˆ–ä¸Šä¼ å›¾ç‰‡", type=["jpg", "png"], key="img_up")
    img_final = img_cam if img_cam else img_up

    if st.button("ğŸ“¡ æ¥æ”¶å–µæ˜Ÿç”µæ³¢", key="btn_audio"):
        if "ğŸš«" in context:
            st.error("âš ï¸ æ— æ³•è§£ç ï¼šè¯·å…ˆåœ¨ä¸Šæ–¹æ§åˆ¶å°é€‰æ‹©ã€ä¿¡å·å‘å°„æºã€‘ï¼")
        elif not audio_file:
            st.error("âš ï¸ è¯·å…ˆä¸Šä¼ å–µå«å£°ï¼")
        else:
            # === å‰§æƒ…æ¨¡å¼åŠ è½½ ===
            loading = st.empty()
            
            # 0% é˜¶æ®µ
            with loading.container():
                st.markdown(render_loading_gif(width=150), unsafe_allow_html=True)
                st.info("ğŸ“¡ æ­£åœ¨è¿æ¥å–µæ˜ŸåŸºç«™...")
                st.progress(0)
            time.sleep(0.5) # å¢åŠ å¾®å°å»¶è¿Ÿè®©ç”¨æˆ·çœ‹æ¸…æ–‡æ¡ˆ

            # 30% é˜¶æ®µ
            with loading.container():
                st.markdown(render_loading_gif(width=150), unsafe_allow_html=True)
                st.info("ğŸ“¶ å‘ç°åŠ å¯†é¢‘ç‡ï¼Œæ­£åœ¨æ¡æ‰‹...")
                st.progress(30)
            
            # æ‰§è¡Œæœ¬åœ°åˆ†æ
            data = analyze_audio_advanced(audio_file, st.session_state['baseline_pitch'])
            
            if data['status'] == 'error':
                loading.empty()
                st.error(f"âŒ å¤±è´¥: {data['msg']}")
            else:
                # 60% é˜¶æ®µ
                with loading.container():
                    st.markdown(render_loading_gif(width=150), unsafe_allow_html=True)
                    st.info("ğŸ§  AI å¤§è„‘æ­£åœ¨ç–¯ç‹‚è¿è½¬...")
                    st.progress(60)

                ai_result = ""
                if ai_ready:
                    try:
                        prompt = f"åœºæ™¯ï¼š{context}ã€‚å£°å­¦ç‰¹å¾ï¼š{data}ã€‚ç¿»è¯‘æˆ‘çš„å¿ƒå£°ã€‚"
                        inputs = [prompt]
                        if img_final: inputs.append(Image.open(img_final))
                        ai_result = model.generate_content(inputs).text
                    except: 
                        st.warning("äº‘ç«¯ä¿¡å·å¼±ï¼Œè½¬ä¸ºç¦»çº¿åˆ†æã€‚")

                # 90% é˜¶æ®µ
                with loading.container():
                    st.markdown(render_loading_gif(width=150), unsafe_allow_html=True)
                    st.info("ğŸ“© ç¿»è¯‘å®Œæˆï¼Œå‡†å¤‡å‘é€ï¼")
                    st.progress(90)
                time.sleep(0.5) # å¢åŠ å¾®å°å»¶è¿Ÿè¥é€ â€œå‘é€â€æ„Ÿ

                loading.empty() # æ¸…é™¤ç­‰å¾…åŠ¨ç”»

                st.success("âœ… ç”µæ³¢æ¥æ”¶æˆåŠŸ")
                c1, c2, c3 = st.columns(3)
                c1.metric("æƒ…ç»ª", data['pitch_trend'].split()[0])
                c2.metric("æ—¶é•¿", f"{data['duration']}s")
                c3.metric("éŸ³é«˜", f"{data['mean_pitch']}Hz")

                st.markdown("### ğŸ± ä¸»å­è¯´ï¼š")
                if ai_result:
                    st.info(f"â€œ {ai_result} â€")
                else:
                    st.info(f"ğŸ¤– æœ¬åœ°æ¨æ–­ï¼šè¿™ä¼¼ä¹æ˜¯ã€{data['pitch_trend']}ã€‘çš„æ„æ€ã€‚")

# === Tab 2: è§†é¢‘ ===
with tab2:
    video_file = st.file_uploader("ä¸Šä¼ è§†é¢‘", type=["mp4", "mov", "avi", "m4v"], key="video_up", label_visibility="collapsed")

    if st.button("ğŸ“¡ æ¥æ”¶è§†é¢‘ä¿¡å·", key="btn_video"):
        if "ğŸš«" in context:
            st.error("âš ï¸ æ— æ³•è§£ç ï¼šè¯·å…ˆåœ¨ä¸Šæ–¹æ§åˆ¶å°é€‰æ‹©ã€ä¿¡å·å‘å°„æºã€‘ï¼")
        elif not video_file:
            st.error("âš ï¸ è¯·å…ˆä¸Šä¼ è§†é¢‘ï¼")
        else:
            loading = st.empty()
            
            # 0% é˜¶æ®µ
            with loading.container():
                st.markdown(render_loading_gif(width=150), unsafe_allow_html=True)
                st.info("ğŸ“¡ æ­£åœ¨è¿æ¥å–µæ˜ŸåŸºç«™...")
                st.progress(0)
            time.sleep(0.5)

            # 30% é˜¶æ®µ
            with loading.container():
                st.markdown(render_loading_gif(width=150), unsafe_allow_html=True)
                st.info("ğŸ“¶ å‘ç°åŠ å¯†é¢‘ç‡ï¼Œæ­£åœ¨æ¡æ‰‹...")
                st.progress(30)

            tfile = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
            tfile.write(video_file.read())
            video_path = tfile.name
            audio_path = video_path.replace(".mp4", ".wav")
            
            has_audio = extract_audio_from_video(video_path, audio_path)
            
            if not has_audio:
                loading.empty()
                st.error("âŒ è§†é¢‘æ— å£°éŸ³")
            else:
                # 60% é˜¶æ®µ
                with loading.container():
                    st.markdown(render_loading_gif(width=150), unsafe_allow_html=True)
                    st.info("ğŸ§  AI å¤§è„‘æ­£åœ¨ç–¯ç‹‚è¿è½¬...")
                    st.progress(60)

                data = analyze_audio_advanced(audio_path, st.session_state['baseline_pitch'])
                ai_msg = ""
                if ai_ready:
                    try:
                        video_blob = genai.upload_file(video_path)
                        while video_blob.state.name == "PROCESSING":
                            time.sleep(1)
                            video_blob = genai.get_file(video_blob.name)
                        
                        prompt = f"åœºæ™¯ï¼š{context}ã€‚å£°éŸ³ï¼š{data}ã€‚ç¿»è¯‘å¿ƒå£°ã€‚"
                        response = model.generate_content([prompt, video_blob])
                        ai_msg = response.text
                    except: pass
                
                # 90% é˜¶æ®µ
                with loading.container():
                    st.markdown(render_loading_gif(width=150), unsafe_allow_html=True)
                    st.info("ğŸ“© ç¿»è¯‘å®Œæˆï¼Œå‡†å¤‡å‘é€ï¼")
                    st.progress(90)
                time.sleep(0.5)

                loading.empty()
                st.success("âœ… å®Œæˆ")
                st.video(video_file)
                st.markdown("### ğŸ± ä¸»å­è¯´ï¼š")
                if ai_msg:
                    st.info(f"â€œ {ai_msg} â€")
                else:
                    st.info("AI æš‚æ—¶ç¦»çº¿ã€‚")
            
            try:
                os.remove(video_path)
                os.remove(audio_path)
            except: pass


