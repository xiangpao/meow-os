import streamlit as st
import google.generativeai as genai
import os
import time
import tempfile
from PIL import Image
from utils import analyze_audio_advanced, extract_audio_from_video

# --- 0. ç³»ç»Ÿé…ç½® (èŒåŒ–ç‰ˆ) ---
st.set_page_config(
    page_title="å–µè¯­ç¿»è¯‘å®˜ ğŸ¾", 
    page_icon="ğŸ±", 
    layout="centered", 
    initial_sidebar_state="collapsed"
)

# æ¸…é™¤ä»£ç†é˜²æ­¢æŠ¥é”™
if "HTTP_PROXY" in os.environ: del os.environ["HTTP_PROXY"]
if "HTTPS_PROXY" in os.environ: del os.environ["HTTPS_PROXY"]

# åˆå§‹åŒ–è®°å¿†
if 'baseline_pitch' not in st.session_state:
    st.session_state['baseline_pitch'] = None

# --- 1. CSS æ·±åº¦ç¾åŒ– (äºŒæ¬¡å…ƒé£æ ¼) ---
st.markdown("""
<style>
    /* å…¨å±€èƒŒæ™¯ï¼šæš–æš–çš„çŒ«çˆªç™½ */
    .stApp {
        background-color: #FFF5EE; 
        background-image: linear-gradient(120deg, #fdfbfb 0%, #ebedee 100%);
    }
    
    /* æ ‡é¢˜å­—ä½“ï¼šå¯çˆ±åœ†ä½“ */
    h1 { 
        color: #FF7F50; 
        font-family: 'Comic Sans MS', 'å¹¼åœ†', sans-serif !important;
        text-shadow: 2px 2px 0px #FFF;
    }
    
    /* å¡ç‰‡å®¹å™¨ï¼šåœ†è§’+é˜´å½± */
    .css-1r6slb0, .stExpander {
        background-color: rgba(255, 255, 255, 0.8);
        border-radius: 20px;
        border: 2px solid #FFDAB9;
        box-shadow: 0 4px 15px rgba(255, 182, 193, 0.3);
    }
    
    /* æŒ‰é’®ï¼šæœå†»è´¨æ„Ÿ */
    .stButton>button {
        background: linear-gradient(45deg, #FF7F50, #FF6347);
        color: white;
        border-radius: 30px;
        height: 55px;
        font-size: 18px;
        font-weight: bold;
        border: none;
        box-shadow: 0 5px 15px rgba(255, 99, 71, 0.4);
        transition: all 0.3s ease;
    }
    .stButton>button:hover {
        transform: scale(1.02);
        box-shadow: 0 8px 20px rgba(255, 99, 71, 0.6);
    }

    /* å­—ä½“ä¼˜åŒ– */
    p, label {
        color: #5D4037;
        font-family: 'PingFang SC', 'Microsoft YaHei', sans-serif;
    }
</style>
""", unsafe_allow_html=True)

# --- 2. é¡¶éƒ¨çœ‹æ¿ä¸è®¾ç½® ---
st.image("https://media1.giphy.com/media/v1.Y2lkPTc5MGI3NjExbDN6eHd4aHlodXZ4aHlodXZ4aHlodXZ4aHlodXZ4aHlodXZ4aHlodXZ4aSZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9cw/Lq0h93752f6J9tijvr/giphy.gif", width=100)
st.title("ğŸ¾ å–µè¯­ç¿»è¯‘å®˜")
st.caption("â€”â€” å¬æ‡‚ä¸»å­æ¯ä¸€å¥â€œå–µâ€èƒŒåçš„å¿ƒæœº")

# ç§‘å­¦åŸç†æŠ˜å åŒº
with st.expander("ğŸ”¬ è¿™ä¸æ˜¯ç©å…·ï¼ç‚¹å‡»æŸ¥çœ‹ç§‘å­¦åŸç†", expanded=False):
    st.markdown("""
    **æœ¬åº”ç”¨åŸºäºç”Ÿç‰©å£°å­¦ (Bio-acoustics) ä¸ å¤šæ¨¡æ€ AI æ„å»ºï¼š**
    1.  **F0 åŸºé¢‘åˆ†æ**ï¼šé€šè¿‡ `Librosa` æå–çŒ«å«å£°çš„æ—‹å¾‹ï¼ˆå‡è°ƒé€šå¸¸ä»£è¡¨è¯·æ±‚ï¼Œé™è°ƒä»£è¡¨æŠ—æ‹’ï¼‰ã€‚
    2.  **æ—¶é•¿ç»´åº¦**ï¼šçŸ­ä¿ƒéŸ³ (<0.5s) å¤šä¸ºç¤¾äº¤ç¡®è®¤ï¼Œé•¿éŸ³ (>1.5s) å¤šä¸ºå¼ºçƒˆéœ€æ±‚ã€‚
    3.  **å¤šæ¨¡æ€èåˆ**ï¼šç»“åˆ `Gemini Vision` è¯†åˆ«è€³/å°¾ä½“æ€ï¼Œä¿®æ­£ç¿»è¯‘å‡†ç¡®ç‡ã€‚
    """)

# è®¾ç½®åŒº
with st.expander("âš™ï¸ åœºæ™¯æ ¡å‡† (å¿…é€‰)", expanded=True):
    context = st.selectbox(
        "ğŸ“ åˆšæ‰å‘ç”Ÿåœ¨å“ªï¼Ÿ",
        ["ğŸ½ï¸ é¥­ç‚¹/å¨æˆ¿ (æœ€å¸¸è§)", "ğŸšª è¢«å…³é—¨å¤–/çª—è¾¹", "ğŸ›‹ï¸ æ’¸çŒ«/æ²™å‘ä¸Š", "ğŸŒ™ æ·±å¤œè·‘é…·", "ğŸ¥ å® ç‰©åŒ»é™¢/å¤–å‡º", "ğŸ¦‹ çª—å¤–æœ‰çŒç‰©"]
    )
    
    c1, c2 = st.columns([2, 1])
    with c1:
        if st.session_state['baseline_pitch']: 
            st.success(f"âœ… å·²è®°å½•ä¸»å­æ ‡å‡†éŸ³é«˜: {st.session_state['baseline_pitch']}Hz")
        else: 
            st.info("ğŸ’¡ å°šæœªè®°å½•æ ‡å‡†éŸ³ã€‚å»ºè®®å½•å…¥ä¸€å£°å¹³æ—¶æœ€æ”¾æ¾çš„å«å£°ä½œä¸ºåŸºå‡†ã€‚")
    with c2:
        if st.button("æ¸…é™¤è®°å¿†"):
            st.session_state['baseline_pitch'] = None
            st.rerun()

# --- 3. è¿æ¥äº‘ç«¯å¤§è„‘ ---
ai_error_msg = ""
try:
    api_key = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=api_key)
    model = genai.GenerativeModel('gemini-1.5-flash')
    ai_ready = True
except Exception as e:
    ai_ready = False
    ai_error_msg = str(e)

if not ai_ready:
    st.error(f"âš ï¸ äº‘ç«¯å¤§è„‘ç¦»çº¿ (ä»…æœ¬åœ°æ¨¡å¼)")
    if "did not find a label" in str(ai_error_msg):
        st.caption("ğŸ”´ åŸå› ï¼šæœªåœ¨ Streamlit åå°é…ç½® API Keyã€‚è¯·å» Manage App -> Settings -> Secrets å¡«å…¥å¯†é’¥ã€‚")
    else:
        st.caption(f"ğŸ”´ åŸå› ï¼š{ai_error_msg}")

# --- 4. æ ¸å¿ƒåŠŸèƒ½ (Tab) ---
tab1, tab2 = st.tabs(["ğŸ™ï¸ è¯­éŸ³ç¿»è¯‘", "ğŸ“¹ è§†é¢‘åŒä¼ "])

# === Tab 1: è¯­éŸ³ ===
with tab1:
    st.markdown("##### 1. å½•ä¸‹ä¸»å­çš„å£°éŸ³")
    audio_file = st.file_uploader("ç‚¹å‡»å½•éŸ³ (æ”¯æŒ m4a/mp3/wav)", type=["wav", "mp3", "m4a", "aac"], label_visibility="collapsed")
    
    st.markdown("##### 2. (å¯é€‰) æ‹å¼ ç…§æé«˜å‡†ç¡®åº¦")
    with st.expander("ğŸ“¸ ç‚¹å‡»å±•å¼€ç›¸æœº", expanded=False):
        img_cam = st.camera_input("æ‹æ‘„çŒ«å’ªè¡¨æƒ…")
    img_up = st.file_uploader("æˆ–ä»ç›¸å†Œä¸Šä¼ ", type=["jpg", "png"], label_visibility="collapsed")
    img_final = img_cam if img_cam else img_up

    if st.button("âœ¨ å¼€å§‹ç¿»è¯‘ âœ¨", key="btn_audio"):
        if not audio_file:
            st.warning("è¯·å…ˆå–‚æˆ‘ä¸€æ®µå½•éŸ³å–µï¼")
        else:
            with st.spinner("ğŸˆ æ­£åœ¨åˆ†æå£°æ³¢ä¸å¾®è¡¨æƒ…..."):
                data = analyze_audio_advanced(audio_file, st.session_state['baseline_pitch'])
                
                if data['status'] == 'error':
                    st.error(f"âŒ è§£æå¤±è´¥: {data['msg']}")
                else:
                    # æ„å»ºæœ¬åœ°é€»è¾‘ç»“è®º (å…œåº•)
                    local_logic = ""
                    if data['duration'] < 0.6: local_logic += " (çŸ­ä¿ƒéŸ³:æ‰“æ‹›å‘¼/ç¡®è®¤)"
                    elif data['duration'] > 1.2: local_logic += " (é•¿éŸ³:éœ€æ±‚/æŠ±æ€¨)"
                    
                    if "Rising" in data['pitch_trend']: local_logic += " + (å‡è°ƒ:ç–‘é—®/è¯·æ±‚)"
                    elif "Falling" in data['pitch_trend']: local_logic += " + (é™è°ƒ:æ‹’ç»/é™ˆè¿°)"
                    
                    # AI åˆ†æ
                    ai_result = ""
                    if ai_ready:
                        try:
                            prompt = f"""
                            ä½ ç°åœ¨å°±æ˜¯è¿™åªçŒ«ã€‚è¯·æ ¹æ®ä»¥ä¸‹æ•°æ®ï¼Œç”¨**ç¬¬ä¸€äººç§°**ç¿»è¯‘ä½ çš„å¿ƒå£°ã€‚
                            
                            ã€ä¼ æ„Ÿå™¨æ•°æ®ã€‘
                            1. åœºæ™¯ï¼š{context}
                            2. å£°éŸ³ç‰¹å¾ï¼š{data['pitch_trend']}ï¼Œæ—¶é•¿{data['duration']}ç§’ï¼Œç²—ç³™åº¦(å˜¶å¼)={'æ˜¯' if data['is_rough'] else 'å¦'}ã€‚
                            3. é€»è¾‘æ¨æ–­å‚è€ƒï¼š{local_logic}
                            
                            ã€è¦æ±‚ã€‘
                            - è¯­æ°”ï¼šå‚²å¨‡ã€å¯çˆ±æˆ–æ€¥åˆ‡ï¼ˆæ ¹æ®æ•°æ®åˆ¤æ–­ï¼‰ã€‚
                            - æ ¼å¼ï¼šç›´æ¥è¯´å‡ºä½ æƒ³è¯´çš„è¯ï¼Œä¸è¦å¸¦å¼•å·ï¼Œä¸è¦è¯´â€œè¿™åªçŒ«â€ã€‚
                            - å¦‚æœåŒ…å«è§†è§‰å›¾ç‰‡ï¼Œè¯·ç»“åˆå›¾ç‰‡ä¸­çš„è€³æœµ/ç³å­”/å°¾å·´çŠ¶æ€ä¿®æ­£ç¿»è¯‘ã€‚
                            """
                            inputs = [prompt]
                            if img_final: inputs.append(Image.open(img_final))
                            ai_result = model.generate_content(inputs).text
                        except Exception as e: st.error(f"AI è¿æ¥ä¸­æ–­: {e}")

                    # ç»“æœå±•ç¤º
                    st.success("âœ… ç¿»è¯‘å®Œæˆ")
                    
                    # èŒåŒ–æ•°æ®å±•ç¤º
                    c1, c2, c3 = st.columns(3)
                    c1.metric("æƒ…ç»ª", data['pitch_trend'].split()[0])
                    c2.metric("éŸ³é•¿", f"{data['duration']}s")
                    c3.metric("å˜¶å¼æŒ‡æ•°", "é«˜!!" if data['is_rough'] else "ä½")

                    st.markdown("### ğŸ± ä¸»å­è¯´ï¼š")
                    if ai_result:
                        st.info(f"â€œ {ai_result} â€")
                    else:
                        # æœ¬åœ°å…œåº•æ–‡æ¡ˆ
                        fallback_msg = "å¿«ç†ç†æˆ‘ï¼" if "Rising" in data['pitch_trend'] else "æœ•ç°åœ¨ä¸æƒ³åŠ¨ã€‚"
                        st.info(f"ï¼ˆAI ä¼‘æ¯ä¸­ï¼‰æœ¬åœ°åˆ†æï¼š{fallback_msg} \n\n *ä¾æ®ï¼š{local_logic}*")

                    # æ ¡å‡†æŒ‰é’®
                    if st.button("ğŸ¯ è¿™å°±æ˜¯å®ƒå¹³æ—¶çš„å£°éŸ³ (è®¾ä¸ºåŸºå‡†)"):
                        st.session_state['baseline_pitch'] = data['mean_pitch']
                        st.toast("è®°ä½äº†å–µï¼ä¸‹æ¬¡ä»¥æ­¤ä¸ºå‡†ã€‚")
                        time.sleep(1)

# === Tab 2: è§†é¢‘ ===
with tab2:
    st.info("ğŸ’¡ æç¤ºï¼šç‚¹å‡»ä¸‹æ–¹é€‰æ‹© **â€œå½•åƒâ€** æˆ– **â€œä»ç›¸å†Œé€‰æ‹©â€**ã€‚")
    video_file = st.file_uploader("ğŸ“¹ ä¸Šä¼ è§†é¢‘", type=["mp4", "mov", "avi", "m4v"], label_visibility="collapsed")

    if st.button("ğŸ¬ è§†é¢‘åŒä¼  ğŸ¬", key="btn_video"):
        if not video_file:
            st.warning("æ²¡æœ‰è§†é¢‘æ€ä¹ˆçœ‹å–µï¼Ÿ")
        else:
            with st.spinner("â³ æ­£åœ¨åˆ†ç¦»éŸ³è½¨å¹¶è¿›è¡Œå¤šæ¨¡æ€åˆ†æ..."):
                tfile = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
                tfile.write(video_file.read())
                video_path = tfile.name
                audio_path = video_path.replace(".mp4", ".wav")
                
                has_audio = extract_audio_from_video(video_path, audio_path)
                
                if not has_audio:
                    st.error("âŒ è§†é¢‘é‡Œæ²¡æœ‰å£°éŸ³å‘€ï¼")
                else:
                    data = analyze_audio_advanced(audio_path, st.session_state['baseline_pitch'])
                    
                    if data['status'] == 'error':
                        st.warning("âš ï¸ è§†é¢‘é‡Œå¥½åƒæ²¡æœ‰çŒ«å«å£°ï¼Ÿå°†ä»…åˆ†æåŠ¨ä½œã€‚")
                        data = {"pitch_trend": "æœªçŸ¥", "mean_pitch": 0, "is_rough": False, "duration": 0}
                    
                    ai_msg = ""
                    if ai_ready:
                        try:
                            video_blob = genai.upload_file(video_path)
                            while video_blob.state.name == "PROCESSING":
                                time.sleep(1)
                                video_blob = genai.get_file(video_blob.name)

                            prompt = f"""
                            ä½ å°±æ˜¯è§†é¢‘é‡Œçš„è¿™åªçŒ«ã€‚
                            ç»“åˆä½ çš„åŠ¨ä½œï¼ˆå°¾å·´/è€³æœµ/å§¿æ€ï¼‰å’Œåˆšæ‰çš„å£°éŸ³æ•°æ®ï¼ˆ{data}ï¼‰ï¼Œ
                            ç”¨**ç¬¬ä¸€äººç§°**å‘Šè¯‰äººç±»ä½ åœ¨æƒ³ä»€ä¹ˆã€‚
                            åœºæ™¯ï¼š{context}ã€‚
                            è¯­æ°”è¦ç”ŸåŠ¨ï¼
                            """
                            response = model.generate_content([prompt, video_blob])
                            ai_msg = response.text
                        except Exception as e: st.error(f"AI ç½¢å·¥äº†: {e}")

                    st.success("âœ… åˆ†æç»“æŸ")
                    st.video(video_file)
                    
                    st.markdown("### ğŸ± ä¸»å­è¯´ï¼š")
                    if ai_msg:
                        st.info(f"â€œ {ai_msg} â€")
                    else:
                        st.info("AI æš‚æ—¶æ— æ³•è¿æ¥ï¼Œæ— æ³•è§£è¯»è§†é¢‘å†…å®¹ã€‚")

                try:
                    os.remove(video_path)
                    os.remove(audio_path)
                except: pass
