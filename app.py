import streamlit as st
import google.generativeai as genai
import os
import time
import tempfile
import base64
from PIL import Image
from utils import analyze_audio_advanced, extract_audio_from_video

# --- 0. ç³»ç»Ÿé…ç½® ---
st.set_page_config(
    page_title="ğŸ± å–µæ˜Ÿç”µæ³¢å°", 
    page_icon="ğŸ“¡", 
    layout="centered", 
    initial_sidebar_state="collapsed"
)

if "HTTP_PROXY" in os.environ: del os.environ["HTTP_PROXY"]
if "HTTPS_PROXY" in os.environ: del os.environ["HTTPS_PROXY"]

# --- 1. è®°å¿†åˆå§‹åŒ– ---
if 'baseline_pitch' not in st.session_state:
    st.session_state['baseline_pitch'] = None

if 'latest_analysis' not in st.session_state:
    st.session_state['latest_analysis'] = None

# --- 2. CSS æ‹¿é“é£å®šåˆ¶ ---
st.markdown("""
<style>
    .stApp {
        background: linear-gradient(180deg, #FFFDF7 0%, #F5E6D3 100%);
        color: #4E342E;
    }
    h1 { 
        color: #5D4037 !important; 
        font-family: 'Comic Sans MS', 'ZKKuaiLe', 'å¹¼åœ†', sans-serif !important;
        font-weight: 800;
        text-shadow: 2px 2px 0px #FFF;
    }
    .stImage, .css-1v0mbdj {
        display: flex;
        justify_content: center;
        align-items: center;
        margin-bottom: -10px;
    }
    .stExpander, .css-1r6slb0, [data-testid="stFileUploadDropzone"] {
        background-color: #FFFFFF !important;
        border-radius: 20px !important;
        border: 2px solid #EFEBE9 !important;
        box-shadow: 0 4px 12px rgba(93, 64, 55, 0.1) !important;
    }
    .stButton>button {
        width: 100%;
        background: linear-gradient(45deg, #D2691E, #8B4513);
        color: white;
        border-radius: 25px;
        height: 55px;
        font-size: 18px;
        font-weight: bold;
        border: none;
        box-shadow: 0 4px 10px rgba(139, 69, 19, 0.3);
        transition: all 0.3s;
    }
    .stButton>button:hover {
        transform: scale(1.02);
        box-shadow: 0 6px 15px rgba(139, 69, 19, 0.5);
        background: linear-gradient(45deg, #E67E22, #A0522D);
    }
    .stTabs [data-baseweb="tab"] {
        background-color: #F5E6D3;
        border-radius: 15px 15px 0 0;
        color: #5D4037;
        font-weight: bold;
    }
    .stTabs [aria-selected="true"] {
        background-color: #FFFFFF;
        border-top: 3px solid #D2691E;
        color: #D2691E;
    }
    p, label, .stMarkdown, li {
        color: #4E342E !important;
        font-family: 'PingFang SC', 'Microsoft YaHei', sans-serif;
    }
    [data-testid="stFileUploadDropzone"] {
        border: 2px dashed #D7CCC8 !important;
    }
</style>
""", unsafe_allow_html=True)

# --- 3. é¡¶éƒ¨çœ‹æ¿ ---
def render_gif(gif_path, width=200):
    try:
        with open(gif_path, "rb") as f:
            data = f.read()
        b64 = base64.b64encode(data).decode()
        st.markdown(f'<div style="text-align: center;"><img src="data:image/gif;base64,{b64}" width="{width}"></div>', unsafe_allow_html=True)
    except:
        st.markdown(f'<div style="text-align: center;"><img src="https://media.tenor.com/4JPf4v6sHjIAAAAj/bongo-cat-typing.gif" width="{width}"></div>', unsafe_allow_html=True)

render_gif("logo.gif")

st.title("ğŸ± å–µæ˜Ÿç”µæ³¢å°")
st.markdown("<p style='text-align: center; margin-top: -15px; color: #8D6E63;'><i>â€”â€” æ¥æ”¶æ¥è‡ª 50Hz é¢‘æ®µçš„åŠ å¯†å¿ƒå£° â€”â€”</i></p>", unsafe_allow_html=True)

# --- ç§‘å­¦åŸç† ---
with st.expander("ğŸ”¬ å–µæ˜Ÿå‘å£°å­¦åŸç† (Science)", expanded=False):
    st.markdown("""
    **æœ¬å°è§£ç ç®—æ³•åŸºäºç‘å…¸éš†å¾·å¤§å­¦ Susanne SchÃ¶tz æ•™æˆçš„çŒ«è¯­æ—‹å¾‹å­¦ç ”ç©¶ï¼š**
    * **ğŸµ å‡è°ƒ (Rising Pitch â†—)**: ç±»ä¼¼ç–‘é—®å¥ï¼Œä»£è¡¨**è¯·æ±‚**æˆ–**ç¡®è®¤**ã€‚
    * **ğŸµ é™è°ƒ (Falling Pitch â†˜)**: ç±»ä¼¼é™ˆè¿°å¥ï¼Œä»£è¡¨**æ‹’ç»**æˆ–**è‡ªä¿¡**ã€‚
    * **â³ æ—¶é•¿**: çŸ­éŸ³(<0.5s)ä¸ºé—®å€™ï¼›é•¿éŸ³(>1s)ä¸ºå¼ºçƒˆéœ€æ±‚ã€‚
    """)

# --- è®¾ç½®ä¸æ ¡å‡†åŒº (æ ¸å¿ƒä¿®æ”¹) ---
with st.expander("âš™ï¸ è°ƒé¢‘ä¸æ ¡å‡† (Settings)", expanded=False):
    # 1. åœºæ™¯é€‰æ‹©
    context = st.selectbox(
        "ğŸ“ ä¿¡å·å‘å°„æº (å½“å‰åœºæ™¯)",
        ["ğŸ½ï¸ å¹²é¥­æ—¶åˆ» (Food)", "ğŸšª é—¨çª—/å—é˜» (Barrier)", "ğŸ›‹ï¸ è´´è´´/æ±‚æ‘¸ (Affection)", "ğŸ¥ å®³æ€•/åº”æ¿€ (Stress)", "ğŸ¦‹ çŒæ€æ—¶åˆ» (Hunting)", "ğŸ˜¡ åˆ«æŒ¨è€å­ (Warning)", "ğŸŒ™ æ·±å¤œè·‘é…· (Night)"]
    )
    
    st.markdown("---")
    st.markdown("**ğŸ›ï¸ å£°çº¹æ ¡å‡†æ§åˆ¶å°**")

    # 2. [æ–°å¢] ç‹¬ç«‹æ ¡å‡†ä¸Šä¼ åŒº
    # è¿™é‡Œå…è®¸ç”¨æˆ·ç›´æ¥ä¸Šä¼ æ–‡ä»¶è¿›è¡Œæ ¡å‡†ï¼Œä¸éœ€è¦å»ä¸‹é¢è·‘æµç¨‹
    calib_file = st.file_uploader(
        "ğŸ™ï¸ ä¸Šä¼ ä¸€æ®µâ€œå¹³æ—¶æœ€æ”¾æ¾çš„å–µå«â€ (ä»…æ ¡å‡†)", 
        type=["wav", "mp3", "m4a", "aac"], 
        key="cal_up",
        label_visibility="visible"
    )
    
    if calib_file:
        if st.button("âš¡ ç«‹å³åˆ†æå¹¶è®¾ä¸ºåŸºå‡†", key="btn_cal_direct"):
            with st.spinner("æ­£åœ¨æå–å£°çº¹ç‰¹å¾..."):
                # è°ƒç”¨æ ¸å¿ƒç®—æ³•ï¼Œä¸ä¼ å…¥åŸºå‡†ï¼Œåªæå–æ•°æ®
                cal_data = analyze_audio_advanced(calib_file, baseline_pitch=None)
                
                if cal_data['status'] == 'error':
                    st.error(f"âŒ æ ¡å‡†å¤±è´¥: {cal_data['msg']}")
                else:
                    new_pitch = cal_data['mean_pitch']
                    st.session_state['baseline_pitch'] = new_pitch
                    st.success(f"âœ… æ ¡å‡†æˆåŠŸï¼å·²é”å®šåŸºå‡†é¢‘ç‡: {new_pitch}Hz")
                    time.sleep(1)
                    st.rerun()

    st.markdown("---")

    # 3. çŠ¶æ€æ˜¾ç¤ºä¸æ¸…é™¤åŒº (åŒæ å¸ƒå±€)
    col_status, col_clear = st.columns([2, 1])
    
    with col_status:
        # å·¦ä¾§ï¼šæ˜¾ç¤ºå½“å‰çŠ¶æ€
        if st.session_state['baseline_pitch']: 
            st.success(f"âœ… å½“å‰åŸºå‡†: {st.session_state['baseline_pitch']}Hz")
        else: 
            st.info("ğŸ’¡ å°šæœªå½•å…¥åŸºå‡†")
            
    with col_clear:
        # å³ä¾§ï¼šæ¸…é™¤æŒ‰é’®
        if st.button("ğŸ—‘ï¸ æ¸…é™¤ç¼“å­˜"):
            st.session_state['baseline_pitch'] = None
            st.rerun()

    # 4. ä¿ç•™â€œä»ç¿»è¯‘ç»“æœæ ¡å‡†â€çš„å¿«æ·æ–¹å¼ (ä¸å†²çªï¼Œå¤šä¸€ç§é€‰æ‹©)
    if st.session_state.get('latest_analysis') and st.session_state['latest_analysis']['type'] == 'audio':
        last_pitch = st.session_state['latest_analysis']['data']['mean_pitch']
        if st.button(f"ğŸ¯ å°†åˆšæ‰çš„ç¿»è¯‘ç»“æœ ({last_pitch}Hz) è®¾ä¸ºåŸºå‡†"):
            st.session_state['baseline_pitch'] = last_pitch
            st.toast(f"åŸºå‡†å·²æ›´æ–°ä¸º {last_pitch}Hz")
            time.sleep(1)
            st.rerun()

# --- è¿æ¥äº‘ç«¯ ---
ai_status_msg = ""
ai_ready = False
try:
    if "GOOGLE_API_KEY" in st.secrets:
        api_key = st.secrets["GOOGLE_API_KEY"]
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-1.5-flash')
        ai_ready = True
    else:
        ai_status_msg = "å¯†é’¥ç¼ºå¤±"
except Exception as e:
    ai_status_msg = str(e)

if not ai_ready:
    st.warning(f"âš ï¸ ä»…æœ¬åœ°æ¨¡å¼ (AI ç¦»çº¿)")

# --- æ ¸å¿ƒåŠŸèƒ½ ---
tab1, tab2 = st.tabs(["ğŸ™ï¸ è¯­éŸ³æ¥æ”¶", "ğŸ“¹ è§†é¢‘åŒä¼ "])

# === Tab 1: è¯­éŸ³ ===
with tab1:
    st.markdown("##### 1. é‡‡é›†å£°æ³¢ (å½•éŸ³/ä¸Šä¼ )")
    audio_file = st.file_uploader("æ”¯æŒ wav/mp3/m4a/aac", type=["wav", "mp3", "m4a", "aac"], key="audio_up", label_visibility="collapsed")
    
    st.markdown("##### 2. (å¯é€‰) å¢åŠ ç…§ç‰‡")
    with st.expander("ğŸ“· å¼€å¯ç›¸æœºæŠ“æ‹", expanded=False):
        img_cam = st.camera_input("æ‹æ‘„çŒ«å’ªè¡¨æƒ…")
    img_up = st.file_uploader("æˆ–ä»ç›¸å†Œä¸Šä¼ å›¾ç‰‡", type=["jpg", "png"], key="img_up", label_visibility="collapsed")
    img_final = img_cam if img_cam else img_up

    if st.button("ğŸ“¡ å¼€å§‹è§£ç ä¿¡å·", key="btn_audio"):
        if not audio_file:
            st.error("è¯·å…ˆä¸Šä¼ ä¸€æ®µå–µå«å£°ï¼")
        else:
            with st.spinner("ğŸˆ æ­£åœ¨ç ´è¯‘åŠ å¯†ç”µæ³¢..."):
                data = analyze_audio_advanced(audio_file, st.session_state['baseline_pitch'])
                
                if data['status'] == 'error':
                    st.error(f"âŒ ä¿¡å·å¹²æ‰°: {data['msg']}")
                else:
                    # æœ¬åœ°é€»è¾‘
                    local_logic = []
                    if data['duration'] < 0.6: local_logic.append("çŸ­ä¿ƒéŸ³(æ‰“æ‹›å‘¼)")
                    elif data['duration'] > 1.2: local_logic.append("é•¿éŸ³(éœ€æ±‚/æŠ±æ€¨)")
                    if "Rising" in data['pitch_trend']: local_logic.append("å‡è°ƒ(ç–‘é—®/è¯·æ±‚)")
                    elif "Falling" in data['pitch_trend']: local_logic.append("é™è°ƒ(æ‹’ç»/é™ˆè¿°)")
                    logic_str = " + ".join(local_logic)

                    # AI åˆ†æ
                    ai_result = ""
                    if ai_ready:
                        try:
                            prompt = f"""
                            è§’è‰²ï¼šä½ å°±æ˜¯è¿™åªçŒ«ã€‚ç”¨ã€ç¬¬ä¸€äººç§°ã€‘ç¿»è¯‘ä½ çš„å¿ƒå£°ã€‚
                            åœºæ™¯ï¼š{context}
                            å£°éŸ³ç‰¹å¾ï¼š{data['pitch_trend']}ï¼Œæ—¶é•¿{data['duration']}ç§’ã€‚
                            é€»è¾‘å‚è€ƒï¼š{logic_str}
                            è¦æ±‚ï¼šè¯­æ°”å‚²å¨‡ã€å¯çˆ±æˆ–æ€¥åˆ‡ã€‚ä¸è¦è¯´â€œè¿™åªçŒ«â€ï¼Œç›´æ¥è¯´â€œæœ¬å–µâ€æˆ–â€œæˆ‘â€ã€‚ç®€çŸ­æœ‰åŠ›ã€‚
                            """
                            inputs = [prompt]
                            if img_final: inputs.append(Image.open(img_final))
                            ai_result = model.generate_content(inputs).text
                        except Exception as e: st.error(f"äº‘ç«¯è¿æ¥ä¸­æ–­: {e}")
                    
                    st.session_state['latest_analysis'] = {
                        "data": data,
                        "ai_result": ai_result,
                        "logic_str": logic_str,
                        "type": "audio"
                    }

    if st.session_state['latest_analysis'] and st.session_state['latest_analysis']['type'] == 'audio':
        res = st.session_state['latest_analysis']
        data = res['data']
        
        st.success("âœ… ç”µæ³¢ç ´è¯‘æˆåŠŸ")
        
        c1, c2, c3 = st.columns(3)
        c1.metric("æƒ…ç»ª", data['pitch_trend'].split()[0])
        c2.metric("æ—¶é•¿", f"{data['duration']}s")
        c3.metric("éŸ³é«˜", f"{data['mean_pitch']}Hz")

        st.markdown("### ğŸ± ä¸»å­è¯´ï¼š")
        if res['ai_result']:
            st.info(f"â€œ {res['ai_result']} â€")
        else:
            st.info(f"ï¼ˆAI ç¦»çº¿ï¼‰æœ¬åœ°æ¨æ–­ï¼šå¤§æ¦‚æ˜¯ã€{res['logic_str']}ã€‘çš„æ„æ€ã€‚")

# === Tab 2: è§†é¢‘ ===
with tab2:
    st.info("ğŸ’¡ æç¤ºï¼šç‚¹å‡»ä¸‹æ–¹æŒ‰é’® -> é€‰æ‹© **â€œå½•åƒâ€** æˆ– **â€œä»å›¾åº“é€‰æ‹©â€**ã€‚")
    video_file = st.file_uploader("ğŸ“¹ ä¸Šä¼ è§†é¢‘æ–‡ä»¶", type=["mp4", "mov", "avi", "m4v"], key="video_up", label_visibility="collapsed")

    if st.button("ğŸ¬ åˆ†æè§†é¢‘ä¿¡å·", key="btn_video"):
        if not video_file:
            st.warning("è¯·å…ˆä¸Šä¼ è§†é¢‘å–µï¼")
        else:
            with st.spinner("ğŸˆ æ­£åœ¨åŒæ­¥è§†è§‰ä¸å¬è§‰ä¿¡å·..."):
                tfile = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
                tfile.write(video_file.read())
                video_path = tfile.name
                audio_path = video_path.replace(".mp4", ".wav")
                
                has_audio = extract_audio_from_video(video_path, audio_path)
                
                if not has_audio:
                    st.error("âŒ è§†é¢‘é‡Œæ²¡æœ‰å£°éŸ³å‘€ï¼")
                else:
                    data = analyze_audio_advanced(audio_path, st.session_state['baseline_pitch'])
                    
                    if data['status'] == 'error':
                        st.warning("âš ï¸ æœªæ£€æµ‹åˆ°çŒ«å«å£°ï¼Œå°†ä»…åˆ†æåŠ¨ä½œã€‚")
                        data = {"pitch_trend": "æœªçŸ¥", "duration": 0, "mean_pitch": 0} 
                    
                    ai_msg = ""
                    if ai_ready:
                        try:
                            video_blob = genai.upload_file(video_path)
                            while video_blob.state.name == "PROCESSING":
                                time.sleep(1)
                                video_blob = genai.get_file(video_blob.name)

                            prompt = f"""
                            è§’è‰²ï¼šä½ å°±æ˜¯è§†é¢‘é‡Œçš„è¿™åªçŒ«ã€‚
                            ä»»åŠ¡ï¼šç»“åˆåŠ¨ä½œï¼ˆå°¾å·´/è€³æœµï¼‰å’Œå£°éŸ³ï¼ˆ{data}ï¼‰ï¼Œç”¨ã€ç¬¬ä¸€äººç§°ã€‘åæ§½æˆ–è¡¨è¾¾éœ€æ±‚ã€‚
                            åœºæ™¯ï¼š{context}ã€‚è¯­æ°”ç”ŸåŠ¨ã€æœ‰è¶£ã€‚
                            """
                            response = model.generate_content([prompt, video_blob])
                            ai_msg = response.text
                        except Exception as e: st.error(f"AI ç½¢å·¥äº†: {e}")

                    st.session_state['latest_analysis'] = {
                        "data": data,
                        "ai_result": ai_msg,
                        "video_path": video_file,
                        "type": "video"
                    }
                
                try:
                    os.remove(video_path)
                    os.remove(audio_path)
                except: pass

    if st.session_state['latest_analysis'] and st.session_state['latest_analysis']['type'] == 'video':
        res = st.session_state['latest_analysis']
        st.success("âœ… å¤šæ¨¡æ€åˆ†æç»“æŸ")
        if video_file: 
            st.video(video_file)
        
        st.markdown("### ğŸ± ä¸»å­è¯´ï¼š")
        if res['ai_result']:
            st.info(f"â€œ {res['ai_result']} â€")
        else:
            st.info("AI æš‚æ—¶æ— æ³•è¿æ¥ã€‚")
